<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2019-09-18T18:06:03+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">NICHOLASJHANA</title><subtitle>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.</subtitle><author><name> </name></author><entry><title type="html">Predicting the next 24 hours of energy demand with machine learning</title><link href="http://localhost:4000/predicting-the-next-24-hours-of-energy-demand-with-machine-learning/" rel="alternate" type="text/html" title="Predicting the next 24 hours of energy demand with machine learning" /><published>2019-04-18T21:34:30+02:00</published><updated>2019-04-18T21:34:30+02:00</updated><id>http://localhost:4000/predicting-the-next-24-hours-of-energy-demand-with-machine-learning</id><content type="html" xml:base="http://localhost:4000/predicting-the-next-24-hours-of-energy-demand-with-machine-learning/">&lt;p&gt;This project investigates various model implementations that predict short-term (24 hour advance) energy demands in the Spanish energy market.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://youtu.be/KaWCwBD_UBA&quot;&gt;Watch the presentation&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;problem-definition-and-motivation&quot;&gt;Problem Definition and Motivation&lt;/h2&gt;
&lt;p&gt;This project is inspired by the paper &lt;a href=&quot;https://arxiv.org/abs/1906.05433&quot;&gt;Tackling Climate Change with Machine Learning&lt;/a&gt; where forecasting is identified as one of the highest impact research areas to contributing to more renewable energy in the grid. Further, it explores the results from &lt;a href=&quot;https://www.researchgate.net/publication/330155110_Short-Term_Load_Forecasting_in_Smart_Grids_An_Intelligent_Modular_Approach&quot;&gt;here&lt;/a&gt; where the authors argue that traditional statistical forecasting is more computationally efficient compared to state of the art approaches. Finally, the last model draws from the data structure, and problem setup in the &lt;a href=&quot;https://www.researchgate.net/publication/323847484_Statistical_and_Machine_Learning_forecasting_methods_Concerns_and_ways_forward&quot;&gt;following paper&lt;/a&gt; to implement a state of the art Long Short Term Network forecast.&lt;/p&gt;

&lt;p&gt;Energy demand forecasting is highly relevant to an effiecnt electrical grid. Improved forecasting is beneficial to deployment of renewable energy, planning for high/low load days, and reducing wastage from polluting on reseve standby generation (typically inefficent gas or coal fired powerplants).&lt;/p&gt;

&lt;h5 id=&quot;project-objectives&quot;&gt;Project objectives&lt;/h5&gt;
&lt;ol&gt;
  &lt;li&gt;Implement classical statistical forecasting models&lt;/li&gt;
  &lt;li&gt;Implement state of the art neural network forecasting models&lt;/li&gt;
  &lt;li&gt;Implement and gain insight into walk forward validation, forecasting performance, and feature selection.&lt;/li&gt;
&lt;/ol&gt;

&lt;h5 id=&quot;problem-summary&quot;&gt;Problem summary&lt;/h5&gt;
&lt;p&gt;The specific problem addressed is to use past energy consumption data, day of the week, holidays, and weather data to once daily predict the next 24 hours of energy demand. This is a highly relevant problem carried out everyday by electrical grid Transmission Service Operators (TSOs) across the world. In order to appropriately meet energy demands TSOs issue energy demand forecasts once a day for the coming 24 hour period. The expected maxium energy demand is forecasted on an hourly basis and consists of 24 hourly slices. These forecasts are used in the planning of supply dispatch, for day-ahead bidding processes, and combined with ultrashort term (6 hours or less) forecasts that maintain balance in the grid.&lt;/p&gt;

&lt;h3 id=&quot;methods-used&quot;&gt;Methods Used&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Data Wrangling&lt;/li&gt;
  &lt;li&gt;Machine Learning&lt;/li&gt;
  &lt;li&gt;Regression&lt;/li&gt;
  &lt;li&gt;Neural Networks&lt;/li&gt;
  &lt;li&gt;Predictive Modelling&lt;/li&gt;
  &lt;li&gt;Walk forward cross validation&lt;/li&gt;
  &lt;li&gt;Hypothesis Testing&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;technologies&quot;&gt;Technologies&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Python&lt;/li&gt;
  &lt;li&gt;Keras, Tensorflow&lt;/li&gt;
  &lt;li&gt;Pandas, Numpy, Jupyter&lt;/li&gt;
  &lt;li&gt;Statsmodels, Scikit-Learn&lt;/li&gt;
  &lt;li&gt;Prophet&lt;/li&gt;
  &lt;li&gt;Joblib, holidays libraries&lt;/li&gt;
  &lt;li&gt;Google Cloud Platform&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;project-description&quot;&gt;Project Description&lt;/h2&gt;
&lt;p&gt;This project compared forecasting capabilities of classical statistical models versus modern neural network implementations on a realistic task of short-term energy demand forecasting. The main question the projec asks is:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;What forecasting model and supervised learning problem formulation gives the lowest MAE given limited computation power constraints&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Timeseries forecasting models implemented in addressing this question are:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;SARIMA - Seasonal Autoregressive Integrated Moving Average&lt;/li&gt;
  &lt;li&gt;Prophet General Additive Model by Facebook&lt;/li&gt;
  &lt;li&gt;Long-Short Term Memory Nerual Network&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;data-sources&quot;&gt;Data sources&lt;/h3&gt;
&lt;p&gt;Energy data was obtained from the &lt;a href=&quot;https://transparency.entsoe.eu/&quot;&gt;ENTSOE Transparency Platform&lt;/a&gt;. The platform provides electrical demand, generation, and price information for all european countries since 2015. Data is available at hourly and daily timeframes.&lt;/p&gt;

&lt;p&gt;Weather data was purchased from &lt;a href=&quot;https://openweathermap.org/api&quot;&gt;OpenWeatherApi&lt;/a&gt;. Data from the five largest cities in spain was pruchased for the previous 8 years. Data includes hourly measurements of temperature (min, max), humidity, preciptation (1h, 3h), snow (1h, 3h), and general descrption of weather status (text format)&lt;/p&gt;

&lt;p&gt;Day of the week and holiday data was genreated using the holidays library. The &lt;a href=&quot;https://github.com/nicholasjhana/short-term-energy-demand-forecasting/blob/master/data_creation_day_types.ipynb&quot;&gt;following notebook&lt;/a&gt; explains how the helper function was implemented. The helper function can be accessed from &lt;a href=&quot;https://github.com/nicholasjhana/short-term-energy-demand-forecasting/blob/master/make_holidays_data.py&quot;&gt;make_holidays_data.py&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;modelling-short-term-energy-demand&quot;&gt;Modelling Short-Term Energy Demand&lt;/h3&gt;

&lt;p&gt;Features used to generate forecasts include autocorrelated hourly energy consumption, hourly weather data, days of the week, and holidays. A detailed decrption of each feature is below:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Energy demand lags ranging between 7 days (168 hours) and 1 month&lt;/li&gt;
  &lt;li&gt;Two PCA vectors generated from weather data&lt;/li&gt;
  &lt;li&gt;Days of the week one hot encoded&lt;/li&gt;
  &lt;li&gt;Holidays one hot encoded&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The output of each model was always the peak expected demand per hour for the next 24 hour period. This forecast was generated from 00:00 each day, over the course of the testing period (see cross validation).&lt;/p&gt;

&lt;h3 id=&quot;supervised-learning-problem&quot;&gt;Supervised learning problem&lt;/h3&gt;
&lt;p&gt;Starting with a univariate sequence of hourly energy demand data points, a supervised learning problem was constructed by shifting data points in such that a previous timestep t-1 was used to predict t. An example of this shifting (also named lagging or lags) is presented in the table below.&lt;/p&gt;

&lt;h5 id=&quot;days-shifted-by-x-steps&quot;&gt;Days shifted by x steps&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Date&lt;/th&gt;
      &lt;th&gt;t&lt;/th&gt;
      &lt;th&gt;t-1&lt;/th&gt;
      &lt;th&gt;t-2&lt;/th&gt;
      &lt;th&gt;t-3&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Day 1:&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Nan&lt;/td&gt;
      &lt;td&gt;Nan&lt;/td&gt;
      &lt;td&gt;Nan&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Day 2:&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Nan&lt;/td&gt;
      &lt;td&gt;Nan&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Day 3:&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;Nan&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Day 4:&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Day 5:&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Day 6:&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Day 7:&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Two variants of this lagging was implemented. The SARIMA and Prophet models used direct lags following the linear sequence of data through time (i.e. to lag one complete day was 24 lags). The neural network used a different structure where one lag represented the same hourly segment, one day prior.&lt;/p&gt;

&lt;h4 id=&quot;sarima--prophet&quot;&gt;SARIMA &amp;amp; Prophet&lt;/h4&gt;
&lt;p&gt;The SARIMA and Prophet models construct the previous time steps by shifting the sequence of energy and weather data one hour at a time and output a sequence of 24 values corresponding with the next day’s demand. The table below describes the learning problem’s structure.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Input Lagged Features&lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Outputs&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;30 Days prior&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;7 days prior&lt;/td&gt;
      &lt;td&gt;2 days prior&lt;/td&gt;
      &lt;td&gt;Previous day&lt;/td&gt;
      &lt;td&gt;»&amp;gt; MODEL »&amp;gt;&lt;/td&gt;
      &lt;td&gt;Forecast&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;h0…h24&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;h0…h24&lt;/td&gt;
      &lt;td&gt;h0…h24&lt;/td&gt;
      &lt;td&gt;h0…h24&lt;/td&gt;
      &lt;td&gt;»&amp;gt; MODEL »&amp;gt;&lt;/td&gt;
      &lt;td&gt;h0 … h24&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;When combined together with may samples the structure of the problem takes on the following shape. Feature vectors are created by lagging the original sequence at different intervals. These vectors are stacked on top of one another by alinging similar lags. One 2D matrix of lagged features consitutes the data needed for a single day’s forecast (one sample). The output as seen in the figure below is a row vector of the 24 hourly predictions.&lt;/p&gt;

&lt;p&gt;&amp;lt;img src=”img/sarima-prophet-data-input.png” width=800 height=400 align=”middle”&amp;gt;&lt;/p&gt;

&lt;h4 id=&quot;lstm&quot;&gt;LSTM&lt;/h4&gt;
&lt;p&gt;The LSTM problem framing was different from the SARIMA and Prophet. The feature input was the same, however the relationship between the shifted features was based on the assumption that each hour of the day had a stronger autocorreltion with the same hour a day prior than the hour prior. The structure of the supervised problem is seen in the table below.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;I/O&lt;/th&gt;
      &lt;th&gt;date&lt;/th&gt;
      &lt;th&gt;h00&lt;/th&gt;
      &lt;th&gt;h01&lt;/th&gt;
      &lt;th&gt;…&lt;/th&gt;
      &lt;th&gt;h23&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Lag features&lt;/td&gt;
      &lt;td&gt;2015-12-01&lt;/td&gt;
      &lt;td&gt;21331.0&lt;/td&gt;
      &lt;td&gt;20622.0&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;25101.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Lag features&lt;/td&gt;
      &lt;td&gt;2016-01-01&lt;/td&gt;
      &lt;td&gt;22431.0&lt;/td&gt;
      &lt;td&gt;21632.0&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;24000.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;⌄⌄⌄⌄⌄&lt;/td&gt;
      &lt;td&gt;⌄⌄⌄⌄⌄&lt;/td&gt;
      &lt;td&gt;⌄⌄⌄⌄⌄&lt;/td&gt;
      &lt;td&gt;⌄⌄⌄⌄⌄&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;LSTM-h0&lt;/td&gt;
      &lt;td&gt;LSTM-h1&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;LSTM-h23&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;⌄⌄⌄⌄⌄&lt;/td&gt;
      &lt;td&gt;⌄⌄⌄⌄⌄&lt;/td&gt;
      &lt;td&gt;⌄⌄⌄⌄⌄&lt;/td&gt;
      &lt;td&gt;⌄⌄⌄⌄⌄&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Forecast&lt;/td&gt;
      &lt;td&gt;2016-01-02&lt;/td&gt;
      &lt;td&gt;22113.0&lt;/td&gt;
      &lt;td&gt;20515.0&lt;/td&gt;
      &lt;td&gt;…&lt;/td&gt;
      &lt;td&gt;26029.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;To formulte this problem using the same data processing as in the SARIMA and Prophet models you would arive at a single data structure per hourly output. In the graphic we see each hourly output has its own 3D input comprised of the lags (previous timestep data), features (energy, weather, day of week), and the sample day of forecast.&lt;/p&gt;

&lt;p&gt;&amp;lt;img src=”img/lstm-data-transform.png” width=800 height=400 align=”middle”&amp;gt;&lt;/p&gt;

&lt;p&gt;The result is computationally intensive for SARIMA and Prophet as you would need to implemente 24 models to solve the supervised learning problem. This implementation is also not feasible in terms of dimensionality with a neural network (LSTM doesn’t accept 4D data).&lt;/p&gt;

&lt;p&gt;The solution, as outlined in &lt;a href=&quot;https://www.researchgate.net/publication/323847484_Statistical_and_Machine_Learning_forecasting_methods_Concerns_and_ways_forward&quot;&gt;one of the motivating papers&lt;/a&gt; is to flatten the features and lags into a single vector. In this way each hourly segment has its own vector containing all the features at the set previous timesteps. The graphic below shows how the alternating green and blue lines represent the various features and lags compressed into a 1D vector.&lt;/p&gt;

&lt;p&gt;&amp;lt;img src=”img/lstm-data-input.png” width=600 height=400 align=”middle”&amp;gt;&lt;/p&gt;

&lt;h3 id=&quot;cross-validation-descrption&quot;&gt;Cross validation descrption&lt;/h3&gt;

&lt;p&gt;Walk forward validation is a standard backtesting methodology when working with timeseries data. The method allows for the validation of test results and reduces overfitting to a small sample of data. The following graphic shows how the whole data set is broken into training and test segments. Once the model has been tested, the previous test segment is introduced into the training data and the model is retrained. Finally the model is tested again on the expanded dataset.&lt;/p&gt;

&lt;p&gt;&amp;lt;img src=”img/walk-forward-validation.png” width=800 height=400 align=”middle”&amp;gt;&lt;/p&gt;

&lt;p&gt;In this project the goal was to have a stadnard training window of 1 year, and a test window of 3 months. Within the training and test sets, a prediction was made once per calendar day. In practice however, this was too computatinoally intensive for the SARIMA, and prophet models given the resources of the project (2 weeks). The intervals were therefore reduced.&lt;/p&gt;

&lt;h2 id=&quot;project-needs-and-core-tasks&quot;&gt;Project needs and core tasks&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;data processing/cleaning
    &lt;ul&gt;
      &lt;li&gt;cleaning of energy data, weather data, and generation of holiday data&lt;/li&gt;
      &lt;li&gt;process data to generate autoregressive features&lt;/li&gt;
      &lt;li&gt;processing data to frame the problem for SARIMA, Prophet, LSTM&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;data exploration
    &lt;ul&gt;
      &lt;li&gt;visualize energy consumption patterns at different temporal scales&lt;/li&gt;
      &lt;li&gt;visualize weather correlations and&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;statistical modeling
    &lt;ul&gt;
      &lt;li&gt;(auto)correlation analysis of model features and feature selection&lt;/li&gt;
      &lt;li&gt;PCA transformation of colinear (weather) features&lt;/li&gt;
      &lt;li&gt;parameter selection for SARIMA model: determining differncing, seasonality, and trend components&lt;/li&gt;
      &lt;li&gt;parameter selection for Prophet model: configure base mode, additional regressors&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;machine learning
    &lt;ul&gt;
      &lt;li&gt;configuration, hyperparmeter tuning, training, and testing of LSTM neural network&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;data pipeline
    &lt;ul&gt;
      &lt;li&gt;helper functions to prepare input, calcualte erros, run walk forward cross validation, and produce visualizations for each model&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;reporting/presentation
    &lt;ul&gt;
      &lt;li&gt;documentation of helper functions&lt;/li&gt;
      &lt;li&gt;presentation of work at live event&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;run-these-models-yourself&quot;&gt;Run these models yourself&lt;/h2&gt;

&lt;p&gt;Each model pipeline may be run independently. To replicate results, or build on this project, you can get started by:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Clone this repo&lt;/li&gt;
  &lt;li&gt;Raw data used for this project Data is found in CSV format within this repo &lt;a href=&quot;Repo folder containing raw data&quot;&gt;here&lt;/a&gt; within this repo.
 a. Updated energy data can be downloaded from the &lt;a href=&quot;https://transparency.entsoe.eu/&quot;&gt;ENTSOE Transparency Platform&lt;/a&gt;
 b. Weather data was obtained from the &lt;a href=&quot;https://openweathermap.org/api&quot;&gt;OpenWeatherApi&lt;/a&gt; and additional data may be purchased.&lt;/li&gt;
  &lt;li&gt;Follow the requirements.yml file to install dependencys&lt;/li&gt;
  &lt;li&gt;Data processing, transformation, and models are found in the main repo.&lt;/li&gt;
  &lt;li&gt;Executing any of the following files will run the designated model:
 a. model_sarima.py
 b. model_prophet.py
 c. model_lstm.py&lt;/li&gt;
  &lt;li&gt;Model output is saved in json for the SARIMA and LSTM. Prophet output is saved in csv.&lt;/li&gt;
  &lt;li&gt;Results folder stores the model outputs under their respective folder names.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;featured-notebooks--deliverables&quot;&gt;Featured Notebooks &amp;amp; Deliverables&lt;/h2&gt;

&lt;h4 id=&quot;models&quot;&gt;Models&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/nicholasjhana/short-term-energy-demand-forecasting/blob/master/model_arima.ipynb&quot;&gt;SARIMA&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/nicholasjhana/short-term-energy-demand-forecasting/blob/master/model_prophet.ipynb&quot;&gt;Prophet&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/nicholasjhana/short-term-energy-demand-forecasting/blob/master/model_lstm.ipynb&quot;&gt;LSTM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;anlysis-and-helper-functions&quot;&gt;Anlysis and Helper Functions&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/nicholasjhana/short-term-energy-demand-forecasting/blob/master/data_analysis.ipynb&quot;&gt;Feature Analysis Energy and Weather&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/nicholasjhana/short-term-energy-demand-forecasting/blob/master/data_features_preprocessing.ipynb&quot;&gt;Data window and transform functions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;communications&quot;&gt;Communications&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/nicholasjhana/short-term-energy-demand-forecasting/blob/master/presentation-short-term-load-forecasting.pdf&quot;&gt;Presentation Deck&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtu.be/KaWCwBD_UBA&quot;&gt;Presentation Video&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;link&quot;&gt;Blog Post&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name> </name></author><summary type="html">This project investigates various model implementations that predict short-term (24 hour advance) energy demands in the Spanish energy market.</summary></entry></feed>